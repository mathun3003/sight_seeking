{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IPjDdAZY1xFzv16SYmPk_Zz5cTPitKzj",
      "authorship_tag": "ABX9TyMqvY2MsMKwsNyMEAGMoMxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathun3003/sight_seeking/blob/main/notebooks/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import logging\n",
        "import time\n",
        "import random\n",
        "import json"
      ],
      "metadata": {
        "id": "GaDCj4KbP_gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount images from gdrive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "imgs_path = \"/Sight_Seeking/data/\"\n",
        "base_path = \"/content/drive/My Drive\"\n",
        "gdrive_path = base_path + imgs_path\n",
        "\n",
        "# imgs dirs\n",
        "dirs = next(os.walk(gdrive_path))[1]\n",
        "# add slash to each dir\n",
        "dirs = [dir + \"/\" for dir in dirs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o7At-ZpsYB0",
        "outputId": "34a53cc7-fe9c-4134-be32-b7723bd198d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create function for image resizing\n",
        "def resize_images_in_dir(dir: str, output_shape: tuple=(224, 224), quality: int=90) -> None:\n",
        "  print(\"Resizing images in {}\".format(dir))\n",
        "  # for every image in dir\n",
        "  for item in os.listdir(dir):\n",
        "    # if it is a file\n",
        "    if os.path.isfile(dir+item):\n",
        "      # open image\n",
        "      im = Image.open(dir+item)\n",
        "      # split file name and file type, discard file type\n",
        "      f, _ = os.path.splitext(dir+item)\n",
        "      # resize img\n",
        "      imResize = im.resize(output_shape, Image.ANTIALIAS)\n",
        "      # if image is not RGB\n",
        "      if imResize.mode in [\"RGBA\", \"P\"]:\n",
        "        # conver to RGB\n",
        "        imResize = imResize.convert(\"RGB\")\n",
        "      # save img\n",
        "      imResize.save(f.replace(\"data/\", \"pp_data/\") + '_resized.jpg', 'JPEG', quality=quality)\n",
        "      # wait until saving succeed\n",
        "      time.sleep(0.5)\n",
        "    else:\n",
        "      raise ValueError(\"Objects has to be a file, not {}\".format(type(item)))\n",
        "  # print \"logs\"\n",
        "  print(f\"\"\"\n",
        "  Number of images before scaling: {len(os.listdir(dir))}\n",
        "  Number of images after scaling: {len(os.listdir(dir.replace(\"data/\", \"pp_data/\")))}\n",
        "  \"\"\")\n",
        "  pass"
      ],
      "metadata": {
        "id": "OVJMGCr0SREz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rescaling images\n",
        "for dir in dirs:\n",
        "  resize_images_in_dir(gdrive_path + dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig9oYZjqb6wW",
        "outputId": "f6fbf1a2-3f91-4414-a77f-a197ee43720f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Schloss_Münster/\n",
            "\n",
            "  Number of images before scaling: 90\n",
            "  Number of images after scaling: 89\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/St._Paulus_Dom_Münster/\n",
            "\n",
            "  Number of images before scaling: 80\n",
            "  Number of images after scaling: 80\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Erbdrostenhof_münster/\n",
            "\n",
            "  Number of images before scaling: 68\n",
            "  Number of images after scaling: 68\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/kiepenkerl_denkmal_münster/\n",
            "\n",
            "  Number of images before scaling: 69\n",
            "  Number of images after scaling: 69\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/LWL-Museum_für_kunst_und_kultur_münster/\n",
            "\n",
            "  Number of images before scaling: 13\n",
            "  Number of images after scaling: 13\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Sankt_Lamberti_Münster/\n",
            "\n",
            "  Number of images before scaling: 72\n",
            "  Number of images after scaling: 72\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Buddenturm_Münster/\n",
            "\n",
            "  Number of images before scaling: 48\n",
            "  Number of images after scaling: 48\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Aaseekugeln_Münster/\n",
            "\n",
            "  Number of images before scaling: 30\n",
            "  Number of images after scaling: 30\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Antiquariat_Münster/\n",
            "\n",
            "  Number of images before scaling: 22\n",
            "  Number of images after scaling: 22\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Provinzial_Münster/\n",
            "\n",
            "  Number of images before scaling: 24\n",
            "  Number of images after scaling: 24\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Cavete_Münster/\n",
            "\n",
            "  Number of images before scaling: 14\n",
            "  Number of images after scaling: 14\n",
            "  \n",
            "Resizing images in /content/drive/My Drive/Sight_Seeking/data/Rathaus_Münster/\n",
            "\n",
            "  Number of images before scaling: 97\n",
            "  Number of images after scaling: 97\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a labels dict to map labels\n",
        "base_dir = '/content/drive/My Drive/Sight_Seeking'\n",
        "directories = os.listdir(base_dir + \"/pp_data\")\n",
        "labels_dict = {l: n for n,l in enumerate(directories)}\n",
        "labels_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHMkthXspNps",
        "outputId": "60132301-8c9c-4924-cdbd-2338bf6ef32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Schloss_Münster': 0,\n",
              " 'St._Paulus_Dom_Münster': 1,\n",
              " 'Erbdrostenhof_münster': 2,\n",
              " 'kiepenkerl_denkmal_münster': 3,\n",
              " 'LWL-Museum_für_kunst_und_kultur_münster': 4,\n",
              " 'Sankt_Lamberti_Münster': 5,\n",
              " 'Buddenturm_Münster': 6,\n",
              " 'Aaseekugeln_Münster': 7,\n",
              " 'Antiquariat_Münster': 8,\n",
              " 'Provinzial_Münster': 9,\n",
              " 'Cavete_Münster': 10,\n",
              " 'Rathaus_Münster': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save labels_dict as json file for mapping after inference\n",
        "with open(base_dir + \"/labels.json\", \"w\") as f:\n",
        "  json.dump(labels_dict, f, indent=4)"
      ],
      "metadata": {
        "id": "HqD3pReLt7ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get number of classes\n",
        "num_classes = len(os.listdir(base_path + \"/Sight_Seeking/pp_data/\"))\n",
        "\n",
        "# Load images and convert them to numpy arrays\n",
        "images, labels = [], []\n",
        "for i, dir in enumerate(directories):\n",
        "  print(\"Collecting images from {}\".format(dir))\n",
        "  label = np.zeros(num_classes)\n",
        "  label[i] = 1\n",
        "  for image_path in os.listdir(base_dir + \"/pp_data/\" + dir):\n",
        "      img = Image.open(base_dir + \"/pp_data/\" + dir + \"/\" + image_path)\n",
        "      # if image is not RGB\n",
        "      if len(img.getbands()) != 3:\n",
        "        # convert to RGB\n",
        "        img = img.convert(\"RGB\")\n",
        "      image_array = np.array(img)\n",
        "      # add image\n",
        "      images.append(image_array)\n",
        "      # add label\n",
        "      labels.append(label)\n",
        "# create trainset\n",
        "dataset = (np.array(images), np.stack(labels, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkxWwIcERrud",
        "outputId": "9511601c-eb9d-4751-e113-74d44dd8f4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting images from Schloss_Münster\n",
            "Collecting images from St._Paulus_Dom_Münster\n",
            "Collecting images from Erbdrostenhof_münster\n",
            "Collecting images from kiepenkerl_denkmal_münster\n",
            "Collecting images from LWL-Museum_für_kunst_und_kultur_münster\n",
            "Collecting images from Sankt_Lamberti_Münster\n",
            "Collecting images from Buddenturm_Münster\n",
            "Collecting images from Aaseekugeln_Münster\n",
            "Collecting images from Antiquariat_Münster\n",
            "Collecting images from Provinzial_Münster\n",
            "Collecting images from Cavete_Münster\n",
            "Collecting images from Rathaus_Münster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the images and labels together\n",
        "images, labels = shuffle(dataset[0], dataset[1], random_state=42)\n",
        "# Split the dataset into a train and test set\n",
        "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "-9xiQX-BtjpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store train and test sets\n",
        "with open(\"/content/drive/My Drive/train_test_sets/images_train.npy\", \"wb\") as f:\n",
        "  np.save(f, images_train)\n",
        "\n",
        "with open(\"/content/drive/My Drive/train_test_sets/images_test.npy\", \"wb\") as f:\n",
        "  np.save(f, images_test)\n",
        "\n",
        "with open(\"/content/drive/My Drive/train_test_sets/labels_train.npy\", \"wb\") as f:\n",
        "  np.save(f, labels_train)\n",
        "\n",
        "with open(\"/content/drive/My Drive/train_test_sets/labels_test.npy\", \"wb\") as f:\n",
        "  np.save(f, labels_test)"
      ],
      "metadata": {
        "id": "1cUgaQ4CtXbI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}